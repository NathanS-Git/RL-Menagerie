# Advantage Actor Critic (A2C) 

Implementation of advantage actor critic

## Contents

- [Behaviour](#behaviour)
- [Results](#results)
- [Runs](#runs)
- [References](#inspired-by--references)

## Behaviour

![Advantage Actor-Critic Algorithm](docs/algorithm.png)


## Runs

To be done.

## Inspired by / References
```bibtex

@misc{ huggingface_reinforce,
    title={Hugging Face Deep RL Course}
    url={https://huggingface.co/learn/deep-rl-course/unit4/hands-on},
    author={Thomas Simonini, et al.},
}

@misc{ openai_spinningup,
    title={OpenAI Spinning Up}
    url={https://spinningup.openai.com/en/latest/spinningup/rl_intro3.html},
    author={Josh Achiam, et al.},
}

@article{DBLP:journals/corr/MnihBMGLHSK16,
  author       = {Volodymyr Mnih and
                  Adri{\`{a}} Puigdom{\`{e}}nech Badia and
                  Mehdi Mirza and
                  Alex Graves and
                  Timothy P. Lillicrap and
                  Tim Harley and
                  David Silver and
                  Koray Kavukcuoglu},
  title        = {Asynchronous Methods for Deep Reinforcement Learning},
  journal      = {CoRR},
  volume       = {abs/1602.01783},
  year         = {2016},
  url          = {http://arxiv.org/abs/1602.01783},
  eprinttype    = {arXiv},
  eprint       = {1602.01783},
  timestamp    = {Mon, 13 Aug 2018 16:47:40 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/MnihBMGLHSK16.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}
```
